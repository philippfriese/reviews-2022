---
version: https://codecheck.org.uk/spec/config/1.0/

manifest:
  - file: NA
    comment: "The AGILE 2022 Reproducibility Review did not include manifest documentation, see https://github.com/codecheckers/register/issues/38"

paper:
  title: "Benchmarking Invasive Alien Species Image Recognition Models for a Citizen Science Based Spatial Distribution Monitoring"
  authors:
    - name: Tom Niers
      ORCID: 0000-0002-5746-8590
    - name: Jan Stenkamp
      ORCID: 0000-0003-1100-4907
    - name: Nick Pascal Jakuschona
      ORCID: 0000-0001-6286-8022
    - name: Thomas Bartoschek
      ORCID: 0000-0002-0882-1036
    - name: Sven Schade
      ORCID: 0000-0001-5677-5209
  reference: https://doi.org/10.5194/agile-giss-3-10-2022

codechecker:
  - name: Daniel NÃ¼st
    ORCID: 0000-0002-0024-5046

report: https://doi.org/10.17605/OSF.IO/K78EB
summary: |
    The article presents a comparison of seven image-based species recognition models, which were benchmarked against a set of species. Selected model executions were successfully reproduced. The outputs were manually compared on a sample basis and match the result data shared privately by the authors; no summary statistics were recalculated.
    The authors provided the used data privately, but all code and good documentation is available online and properly deposited and cited using a data repository.
    Only two of the four online classification APIs were tested due to the requirement of registering accounts, therefore this reproduction is only partially complete.
repository: https://github.com/EibSReM/
check_time: "2022-07-09 12:00:00"
certificate: 2022-008
